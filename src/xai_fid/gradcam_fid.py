import sys
sys.path.extend([
    "./",
])
import os
import torch
import argparse
import hashlib
import  yaml
import ssl
import captum
import matplotlib.pyplot as plt
import numpy as np
import cv2

ssl._create_default_https_context = ssl._create_unverified_context

from src.general_utils import util_data
import src.custom_metrics.preparation as pp
from src.custom_metrics import features
from src.xai_fid.fid_model import FIDModel
import src.custom_metrics.preparation as preparation


def get_parser():

    parser = argparse.ArgumentParser(description='Compute features.')

    parser.add_argument("-cfg", "--cfg_file", type=str, default="./src/configs_features/pneumoniamnist/feat_bin_real.yaml")
    parser.add_argument('--source_dir', type=str, default='./reports/pneumoniamnist', help='Directory name to fake samples.') #/home/lorenzo/GAN-Ensembles/reports/
    parser.add_argument('--dataset_name', type=str, default='pneumoniamnist', choices=['pneumoniamnist', 'retinamnist', 'breastmnist'],  help='The name of dataset')
    parser.add_argument('--gpu_ids', type=str, default='1', help='gpu ids: e.g. 0  use -1 for CPU')
    parser.add_argument('--batch_size', type=int, default='1', help='Batch size')
    parser.add_argument("--post_resizer", type=str, default="friendly", help="which resizer will you use to evaluate GANs in ['legacy', 'clean', 'friendly']")
    parser.add_argument('--eval_backbone', type=str, default='InceptionV3_torch', help="InceptionV3_torch, SwAV_torch, resnet_ae_50_pneumoniamnist, disc_resnet_50_pneumoniamnist, cnn_resnet50_pneumoniamnist, resnet_ae_50_retinamnist, disc_resnet_50_retinamnist, cnn_resnet50_retinamnist, resnet_ae_50_breastmnist, disc_resnet_50_breastmnist, cnn_resnet50_breastmnist ")
    parser.add_argument('--n_samples', type=int, default='4708',  help='Total number of images generated by the ensemble.')

    return parser


# main
if __name__ == '__main__':

    parser = get_parser()
    args, unknown = parser.parse_known_args()

    with open(args.cfg_file) as file:
        cfg = yaml.load(file, Loader=yaml.FullLoader)

    # Directories.
    source_dir = "/Users/valerioguarrasi/Downloads/pneumoniamnist" #args.source_dir #todo: adapt
    dataset_name = args.dataset_name
    samples_dir = os.path.join(source_dir, 'samples')
    cache_dir = os.path.join(source_dir, 'features')
    num_images = 4000

    # Parameters.
    eval_backbone= "resnet_ae_50_pneumoniamnist"# args.eval_backbone #todo: adapt
    post_resizer= args.post_resizer
    batch_size = args.batch_size
    assert batch_size == 1
    max_items = args.n_samples
    # GANs
    gan_folder_name = 'pneumoniamnist-StyleGAN2-train-2023_10_02_17_17_54' #todo: adapt

    filename = f'gradcam_{gan_folder_name}_{eval_backbone}_{post_resizer}'

    # Device.
    gpu_ids = int(args.gpu_ids)
    if gpu_ids >= 0:
        # Check if available.
        if not torch.cuda.is_available():
            device = torch.device('cpu')
        else:
            device = torch.device('cuda:{}'.format(gpu_ids))
    else:
        device = torch.device('cpu')

    # Cache features file.
    cache_dir_real = os.path.join(cache_dir, 'real_train')
    cache_dir_synth = os.path.join(cache_dir, gan_folder_name, 'fake', 'step=100000')
    args = dict(eval_backbone=eval_backbone, post_resizer=post_resizer, max_items=max_items, stats_kwargs={'capture_all': True, 'capture_mean_cov': True})
    md5 = hashlib.md5(repr(sorted(args.items())).encode('utf-8'))
    cache_tag = f"{max_items}-{eval_backbone}-{post_resizer}-{md5.hexdigest()}"
    cache_file_real = os.path.join(cache_dir_real, cache_tag + '.pkl')
    cache_file_synth = os.path.join(cache_dir_synth,  cache_tag + '.pkl')

    eval_model = pp.LoadEvalModel(
        eval_backbone=eval_backbone,
        post_resizer=post_resizer,
        device=device,
        preprocessing=False
    )

    # Dataset
    samples_dir_synth = os.path.join(samples_dir, gan_folder_name, 'fake', 'step=100000')
    dataset = util_data.EnsembleDataset(folders=[samples_dir_synth], weights=[1.0])
    num_batches = len(dataset) // batch_size

    # Dataloder
    dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=False)

    # Load fixed statistics.
    stats_real = features.FeatureStats.load(cache_file_real)
    stats_synt = features.FeatureStats.load(cache_file_synth)
    mu_real, sigma_real = stats_real.get_mean_cov()
    mu_synth, sigma_synth = stats_synt.get_mean_cov()
    # to torch
    mu_real = torch.from_numpy(mu_real).to(device)
    mu_synth = torch.from_numpy(mu_synth).to(device)
    sigma_real = torch.from_numpy(sigma_real).to(device)
    sigma_synth = torch.from_numpy(sigma_synth).to(device)

    # Load model
    eval_model.eval()
    fid_model = FIDModel(feature_extractor=eval_model, num_images=num_images, mu_real=mu_real, mu_synth=mu_synth, sigma_real=sigma_real, sigma_synth=sigma_synth)
    fid_model.eval()

    data_iter = iter(dataloader)
    for _ in range(0, num_batches):
        try:
            x, labels = next(data_iter)
        except StopIteration:
            break

        x, labels = x.to(device), labels.to(device)
        x = torch.clamp(x, -1, 1) # Clip between -1 and 1
        original_x = x.clone()
        x.requires_grad = False
        quantize = True

        # Preprocessing
        if eval_backbone == "InceptionV3_torch":
            if x.shape[1] != 3:
                x = x.repeat(1, 3, 1, 1)  # grayscale to RGB
            if quantize:
                x = preparation.quantize_images(x)
            else:
                x = x.detach().cpu().numpy().astype(np.uint8)
            x = preparation.resize_images(x, eval_model.resizer, eval_model.totensor, eval_model.mean, eval_model.std, device=eval_model.device)

        # Compute fid
        fid = fid_model(x)

        # Choose layer #todo: adapt for each backbone
        if eval_backbone == "InceptionV3_torch":
            layer = fid_model.feature_extractor.model.Mixed_7c
        elif eval_backbone == "SwAV_torch":
            layer = None
        elif eval_backbone == "resnet_ae_50_pneumoniamnist":
            layer = fid_model.feature_extractor.model.layer4

        # Gradcam
        guided_gc = captum.attr.GuidedGradCam(fid_model, layer)
        attributions = guided_gc.attribute(x, interpolate_mode='bilinear')

        # Convert the attributions to a numpy array
        attributions = attributions.squeeze().cpu().detach().numpy()
        if len(attributions.shape) == 2:
            attributions = np.expand_dims(attributions, axis=0)

        # Upsample the Grad-CAM heatmap to the size of the original image
        heatmap = np.interp(attributions, (attributions.min(), attributions.max()), (0, 1))

        original_image = original_x[0].detach().cpu().numpy().squeeze()

        # Convert the grayscale image to a 3-channel image
        normalized_image = ((original_image - np.min(original_image)) / (np.max(original_image) - np.min(original_image))) * 255
        # Resize the image to match the size of the original image
        normalized_image = cv2.resize(normalized_image, (x[0].shape[1], x[0].shape[1]))
        # Convert to 8-bit integer format
        normalized_image_8bit = np.uint8(normalized_image)
        # Convert to 3-channel grayscale image
        original_image_3channel = cv2.cvtColor(normalized_image_8bit, cv2.COLOR_GRAY2RGB)

        # Convert the heatmap to a colormap representation
        heatmap_colored = cv2.applyColorMap(np.uint8(255 * heatmap.transpose(1, 2, 0)), cv2.COLORMAP_JET)

        # Overlay the heatmap on the 3-channel grayscale image with a certain transparency level
        overlayed_image = cv2.addWeighted(original_image_3channel, 0.6, heatmap_colored, 0.4, 0)

        # Plot
        plt.figure(figsize=(10, 5))
        # Display original image
        plt.subplot(1, 2, 1)
        plt.imshow(original_image_3channel, cmap='gray')
        plt.axis('off')
        # Display heatmap
        plt.subplot(1, 2, 2)
        plt.imshow(overlayed_image, cmap='jet')
        plt.axis('off')
        plt.tight_layout()
        #plt.savefig() #todo: adapt
        plt.show()

    print("May the force be with you.")
