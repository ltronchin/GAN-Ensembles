import copy
import sys
sys.path.extend([
    "./"
])
import numpy as np
import os
import optuna
import seaborn as sns
import hashlib
import uuid
import re
import argparse
import copy
from tqdm import tqdm
import pandas as pd
import datetime

# Downstream task.
import yaml
import torch
import torch.nn as nn
import torch.optim as optim
from torch.optim import lr_scheduler
import collections

from src.data_util import Dataset_
from src.general_utils.util_data import EnsembleDataset
from src.cnn_models.models import ResNet18, ResNet50
from src.general_utils import util_cnn

from src.custom_metrics.features import FeatureStats
from src.custom_metrics.features import load_stats

from src.general_utils import util_path
from src.general_utils import util_general
from src.general_utils import util_ensemble
from src.general_utils import util_metric

# For aspect ratio 4:3.
sns.set_context("paper")
sns.set_theme(style="ticks")

def get_parser():

    parser = argparse.ArgumentParser(description='Ensemble search.')

    parser.add_argument('--source_dir', type=str, default='./reports/pneumoniamnist', help='Directory name to fake samples.')
    parser.add_argument('--dataset_name', type=str, default='pneumoniamnist',  choices=['retinamnist', 'pneumoniamnist', 'breastmnist', 'AIforCOVID', 'organamnist'], help='The name of dataset')
    parser.add_argument('--gpu_ids', type=str, default='0', help='gpu ids: e.g. 0  0,1,2, 0,2. use -1 for CPU')
    # GANs params.
    parser.add_argument('--gan_models', type=util_general.parse_comma_separated_list, default='MHGAN,SNGAN,StyleGAN2-D2DCE,ReACGAN-ADA,ReACGAN-ADC,ReACGAN-DiffAug,ACGAN-Mod,ReACGAN,BigGAN-DiffAug,BigGAN-Info,StyleGAN2-DiffAug,ACGAN-Mod-TAC,BigGAN,ReACGAN-TAC,BigGAN-ADA,StyleGAN2-Info,ACGAN-Mod-ADC,StyleGAN2-ADA,ReACGAN-Info,StyleGAN2,ContraGAN,SAGAN', help='List of GANs to enable in the ensemble') #ACGAN-Mod-ADC,SAGAN,ReACGAN-ADA,StyleGAN2-DiffAug,StyleGAN2  # MHGAN,SNGAN,StyleGAN2-D2DCE,ReACGAN-ADA,ReACGAN-ADC,ReACGAN-DiffAug,ACGAN-Mod,ReACGAN,BigGAN-DiffAug,BigGAN-Info,StyleGAN2-DiffAug,ACGAN-Mod-TAC,BigGAN,ReACGAN-TAC,BigGAN-ADA,StyleGAN2-Info,ACGAN-Mod-ADC,StyleGAN2-ADA,ReACGAN-Info,StyleGAN2,ContraGAN,SAGAN
    #parser.add_argument('--gan_models', type=util_general.parse_comma_separated_list, default='MHGAN,SNGAN,StyleGAN2-D2DCE,ReACGAN-ADA', help='List of GANs to enable in the ensemble')
    parser.add_argument('--gan_steps', type=util_general.parse_comma_separated_list, default='20000,40000,60000,80000,100000',help='Iter or Iters to sample each GAN') #20000,40000 # 20000,40000,60000,80000,100000
    parser.add_argument("--post_resizer", type=str, default="friendly", help="which resizer will you use to evaluate GANs in ['legacy', 'clean', 'friendly']")
    parser.add_argument('--eval_backbone', type=str, default='SwAV_torch',  choices=['InceptionV3_torch', 'ResNet50_torch', 'SwAV_torch', 'InceptionV3_torch__medical',  'InceptionV3_torch__truefake', 'ResNet50_torch__medical', 'ResNet50_torch__truefake'])
    parser.add_argument('--n_samples', type=int, default='4708', help='Total number of images generated by the ensemble.')
    parser.add_argument('--split', type=str, default='train', choices=['train', 'val'])
    # Ensemble search params.
    parser.add_argument('--name_obj', type=str, default='dc_inter__dc_intra', choices=['dc_inter', 'pr_inter', 'fid_inter', 'dc_inter__dc_intra', 'pr_inter__pr_intra', 'fid_inter__fid_intra'])
    parser.add_argument('--pairwise_intra', type=bool, default=True)
    #parser.add_argument('--pairwise_intra_df', type=bool, default=True)
    parser.add_argument('--n_trial', type=int, default=1000)
    parser.add_argument('--dim_reduction', type=bool, default=False)
    parser.add_argument('--synth_samples_reduction', type=int, default=100000)
    # Downstream task params.
    parser.add_argument("-cfg", "--cfg_file", type=str, default="./src/configs_downstream_task/pneumoniamnist.yaml")
    parser.add_argument('--init_w', type=str, default='uniform', choices=['uniform', 'random', 'fid'],  help='Weight initialization')
    parser.add_argument('--n_train', type=int, default=20, help='Number of times the experiment is repeated.')
    parser.add_argument("--num_workers", type=int, default=8)

    return parser

if __name__ == '__main__':


    parser = get_parser()
    args, unknown = parser.parse_known_args()

    # Directories.
    source_dir = args.source_dir
    dataset_name = args.dataset_name
    samples_dir = os.path.join(source_dir, 'samples')
    ensemble_dir = os.path.join(source_dir, 'ensemble')
    reports_dir = os.path.join(source_dir, 'downstream_task_pareto')
    util_path.create_dir(reports_dir)

    # Parameters features.
    post_resizer = args.post_resizer
    eval_backbone = args.eval_backbone
    n_samples = args.n_samples
    split = args.split

    # Parameters ensemble.
    name_obj = args.name_obj
    n_trial = args.n_trial
    pairwise_intra = args.pairwise_intra
    dim_reduction = args.dim_reduction
    synth_samples_reduction = args.synth_samples_reduction

    gan_models = args.gan_models
    gan_steps = args.gan_steps
    gan_aval = os.listdir(samples_dir)
    gan_folders = [os.path.join(samples_dir, x, f'fake__{split}') for x in gan_aval if any(f'{gan_model}-train-' in x for gan_model in gan_models)]
    gan_folders = [os.path.join(x, f"step={y}") for x in gan_folders for y in gan_steps]

    # Downstram task params.
    with open(args.cfg_file) as file:
        cfg = yaml.load(file, Loader=yaml.FullLoader)

    init_w = args.init_w
    n_train = args.n_train
    img_size = cfg['DATA']['img_size']
    gpu_ids = int(args.gpu_ids)
    num_workers = args.num_workers

    # Device.
    if gpu_ids >= 0:
        # Check if available.
        if not torch.cuda.is_available():
            device = torch.device('cpu')
        else:
            device = torch.device('cuda:{}'.format(gpu_ids))
    else:
        device = torch.device('cpu')

    # Add to the filename the current time.
    filename = f'ensemble_search-n_trial__{n_trial}-name_obj__{name_obj}-pairwise_intra__{pairwise_intra}-dim_reduction__{dim_reduction}-synth_samples_reduction__{synth_samples_reduction}-{eval_backbone}-{post_resizer}-{n_samples}'

    try:
        from paretoset import paretoset
        df = pd.read_excel(os.path.join(os.path.join(ensemble_dir, filename), 'optuna_study.xlsx'), engine='openpyxl')

        df_vals = df[['values_0', 'values_1']].to_numpy()
        mask = paretoset(df_vals, sense=["max", "min"])
        df_vals_paretoset = df_vals[mask]
        df_paretoset = df[mask]
        df_paretoset.to_excel(os.path.join(ensemble_dir, filename, 'pareto_solutions.xlsx'), index=False)
    except FileNotFoundError:
        print("File not found. Exit...")
        exit()

    for idx in range(len(df_paretoset)):
        print(f"Training {idx + 1}/{len(df_paretoset)}...")
        df_paretoset_idx = df_paretoset.iloc[idx]
        gans_pareto_idx =  df_paretoset_idx.filter(like='params_')
        number_idx = df_paretoset_idx.filter(like='number').values[0]

        # Filter in the dataframe elements equal to zero.
        best_trials = gans_pareto_idx[gans_pareto_idx != 0]
        best_trials_name = list(best_trials.keys())

        # Filter the gan folders.
        sel_folders = []
        for x in best_trials_name:
            parts = x.split('__')
            step = parts[-1]
            mod = parts[0].split('_')[-1]
            for y in gan_folders:
                # Append to sel_folders only if y fully contains both step and mod.
                y_mod = y.split('/')[-3].split('-train')[0].split(f'{dataset_name}-')[-1]
                y_step = y.split('/')[-1].split('=')[-1]
                if y_step == step and y_mod == mod:
                    sel_folders.append(y)
                    break
        assert len(sel_folders) == len(best_trials_name), "The number of selected folders is not equal to the number of selected trials."

        # Directories.
        filename = f'downstream_task_ensemble_pareto-pareto_idx__{number_idx}-n_trial__{n_trial}-name_obj__{name_obj}-pairwise_intra__{pairwise_intra}-dim_reduction__{dim_reduction}-synth_samples_reduction__{synth_samples_reduction}-{eval_backbone}-{post_resizer}-{n_samples}'
        reports_dir_idx = os.path.join(reports_dir, filename)
        util_path.create_dir(reports_dir_idx)
        with open(os.path.join(reports_dir_idx, f"ensemble.txt"), 'w') as f:
            f.write(f"\nEnsemble: {best_trials_name}")
            f.write("\n")
            f.write(f"\nFolder ensemble: {sel_folders}")

        datasets_real = {
            step: Dataset_(
                    data_name=cfg['DATA']['name'],
                    data_dir=cfg['DATA']['data_dir'],
                    train=True if step == 'train' else False,
                    split=step,
                    crop_long_edge=cfg['PRE']['crop_long_edge'],
                    resize_size=cfg['PRE']['resize_size'],
                    resizer=cfg['PRE']['pre_resizer'],
                    random_flip=cfg['PRE']['apply_rflip'],
                    normalize=cfg['PRE']['normalize'],
                    hdf5_path=os.path.join(cfg['DATA']['hdf5'], f'{dataset_name}_{img_size}_{step}.hdf5') if cfg['DATA']['hdf5'] is not None else None,
                    load_data_in_memory=cfg['DATA']['load_data_in_memory'],
                    cfgs=cfg) for step in ['train', 'val', 'test']
        }

        if dataset_name == 'AIforCOVID':
            classes = cfg['DATA']['classes']
            class_to_idx = {c: i for i, c in enumerate(sorted(classes))}
            idx_to_class = {i: c for c, i in class_to_idx.items()}

            weight = [
                len(datasets_real['train']) / (len(classes) * len(datasets_real['train'].labels[datasets_real['train'].labels == class_to_idx[c]])) for c in classes
            ]
        elif dataset_name in ['pneumoniamnist', 'breastmnist', 'retinamnist']:
            idx_to_class = datasets_real['test'].data.info['label']
            idx_to_class = {int(k): v for k, v in idx_to_class.items()}
            class_to_idx = {v: k for k, v in idx_to_class.items()}
            classes = [idx_to_class[i] for i in range(len(idx_to_class))]
            weight = [
                len(datasets_real['train'].data) / (len(classes) * len(datasets_real['train'].data.labels[datasets_real['train'].data.labels == class_to_idx[c]])) for c in classes
            ]
        else:
            raise NotImplementedError

        # Synthetic data.
        weights = util_ensemble.initialize_ensemble_weights(init_w=init_w, gan_list=sel_folders)
        dataset_synth = EnsembleDataset(folders=sel_folders, weights=weights)
        datasets = {
            'train': dataset_synth,
            'val': datasets_real['val'],
            'test': datasets_real['test']
        }

        data_loaders = {
            'train': torch.utils.data.DataLoader(datasets['train'], batch_size=cfg['TRAINER']['batch_size'], shuffle=True, num_workers=num_workers),
            'val': torch.utils.data.DataLoader(datasets['val'], batch_size=cfg['TRAINER']['batch_size'], shuffle=False, num_workers=num_workers),
            'test': torch.utils.data.DataLoader(datasets['test'], batch_size=cfg['TRAINER']['batch_size'], shuffle=False, num_workers=num_workers)
        }

        # List to save results for each training.
        results = collections.defaultdict(lambda: [])
        for idx_train in np.arange(n_train):
            results['Training'].append(idx_train)
            print(f"Training {idx_train + 1}/{n_train}...")

            print('==> Building and training model...')
            if cfg['MODEL']['name'] == 'resnet18':
                model = ResNet18(input_channels=cfg['DATA']['img_channels'], num_classes=cfg['DATA']['num_classes'])
            elif cfg['MODEL']['name'] == 'resnet50':
                model = ResNet50(input_channels=cfg['DATA']['img_channels'], num_classes=cfg['DATA']['num_classes'])
            else:
                raise NotImplementedError
            model = model.to(device)

            # Loss function.
            criterion = nn.CrossEntropyLoss(weight=torch.Tensor(weight)).to(device)
            optimizer = optim.Adam(model.parameters(), lr=cfg['TRAINER']['optimizer']['lr'])
            scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode=cfg['TRAINER']['scheduler']['mode'],  patience=cfg['TRAINER']['scheduler']['patience'])

            model, history = util_cnn.train_model(
                model=model,
                data_loaders=data_loaders,
                criterion=criterion,
                optimizer=optimizer,
                scheduler=scheduler,
                num_epochs=cfg['TRAINER']['max_epochs'],
                early_stopping=cfg['TRAINER']['early_stopping'],
                warmup_epoch=cfg['TRAINER']['warmup_epoch'],
                model_dir=reports_dir_idx,
                device=device,
                n_samples=n_samples,
                to_disk=False
            )

            # Plot Training.
            util_cnn.plot_training(history=history, plot_training_dir=reports_dir_idx, plot_name_loss=f'Loss_training_{idx_train}', plot_name_acc=f'Acc_training_{idx_train}')

            # Test model.
            test_results = util_cnn.evaluate(model=model, data_loader=data_loaders['test'], device=device, idx_to_class=idx_to_class)

            # Update report.
            results["ACC"].append(test_results['all'])
            for c in classes:
                results["ACC %s" % str(c)].append(test_results[c])
            results['recall'].append(test_results['recall'])
            results['precision'].append(test_results['precision'])
            results['specificity'].append(test_results['specificity'])
            results['f1_score'].append(test_results['f1_score'])
            results['g_mean'].append(test_results['g_mean'])

            # Save results
            reports_file = os.path.join(reports_dir_idx, f'results_training_{idx_train}.xlsx')
            results_frame = pd.DataFrame(dict([(k, pd.Series(v)) for k, v in results.items()]))
            results_frame.to_excel(reports_file, index=False)

        # Compute mean and std.
        results_frame = pd.DataFrame(dict([(k, pd.Series(v)) for k, v in results.items()]))
        results_frame.loc['mean'] = results_frame.mean()
        results_frame.loc['std'] = results_frame.std()

        # Add mean and std of all metrics to df_paretoset dataframe at the corresponding index.
        df_paretoset.loc[number_idx, 'ACC'] = results_frame.loc['mean']['ACC']
        df_paretoset.loc[number_idx, 'recall'] = results_frame.loc['mean']['recall']
        df_paretoset.loc[number_idx, 'precision'] = results_frame.loc['mean']['precision']
        df_paretoset.loc[number_idx, 'specificity'] = results_frame.loc['mean']['specificity']
        df_paretoset.loc[number_idx, 'f1_score'] = results_frame.loc['mean']['f1_score']
        df_paretoset.loc[number_idx, 'g_mean'] = results_frame.loc['mean']['g_mean']

        # Save Results
        reports_file = os.path.join(reports_dir_idx, 'results.xlsx')
        results_frame.to_excel(reports_file, index=True)

        # Save paretoset results.
        df_paretoset.to_excel(os.path.join(reports_dir, f'pareto_solutions-{name_obj}-{eval_backbone}.xlsx'), index=False)

    print("May the force be with you.")