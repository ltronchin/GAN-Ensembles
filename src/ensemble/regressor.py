import sys
sys.path.extend([
    "./",
])
import os
import torch
from itertools import combinations
from tqdm import tqdm
import math
import time
import scipy
import numpy as np
import pandas as pd
import uuid
import argparse


def get_parser():

    parser = argparse.ArgumentParser(description='Compute features.')

    parser.add_argument('--reports_dir', type=str, default='./reports/pneumoniamnist/ensemble/', help='Directory name to fake samples.') #/home/lorenzo/GAN-Ensembles/reports/pneumoniamnist #./reports/pneumoniamnist
    parser.add_argument('--dataset_name', type=str, default='pneumoniamnist', choices=['pneumoniamnist'],    help='The name of dataset')
    parser.add_argument("--post_resizer", type=str, default="friendly", help="which resizer will you use to evaluate GANs in ['legacy', 'clean', 'friendly']")
    parser.add_argument('--eval_backbone', type=str, default='cnn_resnet_50_pneumoniamnist', help="[InceptionV3_torch, ResNet50_torch, SwAV_torch, resnet_ae_50_pneumoniamnist, disc_resnet_50_pneumoniamnist, cnn_resnet_50_pneumoniamnist")
    parser.add_argument('--n_samples', type=int, default='50000',  help='Total number of images generated by the ensemble.')
    parser.add_argument('--split', type=str, default='train', choices=['train', 'val'])
    return parser

# main
if __name__ == '__main__':

    parser = get_parser()
    args, unknown = parser.parse_known_args()

    # Directories.
    reports_dir = args.reports_dir

    # Parameters.
    dataset_name = args.dataset_name
    eval_backbone = args.eval_backbone
    post_resizer = args.post_resizer
    n_samples = args.n_samples
    split = args.split

    # Load the dataset.
    filename_prdc = f'history_prdc_bin_real_{split}_{eval_backbone}_{post_resizer}_{n_samples}'
    filename_fid = f'history_fid_bin_real_{split}_{eval_backbone}_{post_resizer}_{n_samples}'

    # Load excel file.
    df_prdc = pd.read_excel(os.path.join(reports_dir, f'{filename_prdc}.xlsx'), engine='openpyxl')
    df_fid = pd.read_excel(os.path.join(reports_dir, f'{filename_fid}.xlsx'), engine='openpyxl')
    df_rep = pd.read_excel(os.path.join(reports_dir, f'{dataset_name}_overall_reports.xlsx'), engine='openpyxl')

    gan_list = list(df_prdc['gan0'])
    step_list = list(df_prdc['step0'])

    # Select ['prc', 'rec', 'dns', 'cvg'] columns from dataframe.
    df_prdc = df_prdc[['prc', 'rec', 'dns', 'cvg']]

    # Select ['fid'] column from dataframe.
    df_fid = df_fid[['fid']]

    # Select 'ACC' column from dataframe.
    df_rep = df_rep[['ACC']]

    # Merge the dataframe
    df = pd.concat([df_prdc, df_fid, df_rep], axis=1)

    # Train a Sklearn regressor to predict the ACC from the other metrics.
    from sklearn.linear_model import LinearRegression
    from sklearn.model_selection import train_test_split

    # Split the dataframe into train and test.
    X = df[['prc', 'rec', 'dns', 'cvg', 'fid']]
    y = df[['ACC']]

    # Split the dataframe into train and test.
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    # Train the regressor.
    reg = LinearRegression().fit(X_train, y_train)

    # Predict the test set.
    y_pred = reg.predict(X_test)

    # Compute the R2 score.
    from sklearn.metrics import r2_score
    r2_score(y_test, y_pred)

    # Save the regressor.


    print("May be the force with you.")

