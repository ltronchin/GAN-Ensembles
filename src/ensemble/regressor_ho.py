import sys
sys.path.extend([
    "./",
])
import os
import torch
from itertools import combinations
from tqdm import tqdm
import math
import time
import scipy
import numpy as np
import pandas as pd
import uuid
import argparse

from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import r2_score
import pickle

def get_parser():

    parser = argparse.ArgumentParser(description='Compute features.')

    parser.add_argument('--reports_dir', type=str, default='./reports/pneumoniamnist/ensemble/', help='Directory name to fake samples.') #/home/lorenzo/GAN-Ensembles/reports/pneumoniamnist #./reports/pneumoniamnist
    parser.add_argument('--dataset_name', type=str, default='pneumoniamnist', choices=['pneumoniamnist'],    help='The name of dataset')
    parser.add_argument("--post_resizer", type=str, default="friendly", help="which resizer will you use to evaluate GANs in ['legacy', 'clean', 'friendly']")
    parser.add_argument('--eval_backbone', type=str, default='cnn_resnet_50_pneumoniamnist', help="[InceptionV3_torch, ResNet50_torch, SwAV_torch, resnet_ae_50_pneumoniamnist, disc_resnet_50_pneumoniamnist, cnn_resnet_50_pneumoniamnist")
    parser.add_argument('--n_samples', type=int, default='50000',  help='Total number of images generated by the ensemble.')
    parser.add_argument('--split', type=str, default='train', choices=['train', 'val'])
    return parser

# main
if __name__ == '__main__':

    parser = get_parser()
    args, unknown = parser.parse_known_args()

    # Directories.
    reports_dir = args.reports_dir

    # Parameters.
    dataset_name = args.dataset_name
    eval_backbone = args.eval_backbone
    post_resizer = args.post_resizer
    n_samples = args.n_samples
    split = args.split
    model_name = 'rf' # dt, rfl, lg

    # Load the dataset.
    filename_prdc = f'history_prdc_bin_real_{split}_{eval_backbone}_{post_resizer}_{n_samples}'
    filename_fid = f'history_fid_bin_real_{split}_{eval_backbone}_{post_resizer}_{n_samples}'

    # Load excel file.
    df_prdc = pd.read_excel(os.path.join(reports_dir, f'prdc/{filename_prdc}.xlsx'), engine='openpyxl')
    df_fid = pd.read_excel(os.path.join(reports_dir, f'fid/{filename_fid}.xlsx'), engine='openpyxl')
    df_rep = pd.read_excel(os.path.join(reports_dir, f'{dataset_name}_overall_reports.xlsx'), engine='openpyxl')

    gan_list_prdc = list(df_prdc['gan0'])
    step_list_prdc = list(df_prdc['step0'])
    gan_list_fid = list(df_prdc['gan0'])
    step_list_fid = list(df_prdc['step0'])

    assert gan_list_prdc == gan_list_fid
    assert step_list_prdc == step_list_fid

    gan_list = gan_list_prdc
    step_list = step_list_prdc

    df_rep_ord = pd.DataFrame(columns=['gan', 'step', 'ACC'])
    for gan, step in zip(gan_list, step_list):
        print(gan)
        print(step)
        row = df_rep[(df_rep['gan'] == gan) & (df_rep['step'] == str(step))]

        for index, row in row.iterrows():
            df_rep_ord = df_rep_ord.append({'gan': gan, 'step': step, 'ACC': row['ACC']}, ignore_index=True)

    df = pd.concat([df_prdc[['prc', 'rec', 'dns', 'cvg']],  df_fid[['fid']], df_rep_ord['ACC']], axis=1)

    X = df[['prc', 'rec', 'dns', 'cvg', 'fid']]
    y = df[['ACC']]

    # Split the dataframe into train and test.
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    # Standardize
    scaler = StandardScaler()
    scaler.fit(X_train)
    X_train = scaler.transform(X_train)
    X_test  = scaler.transform(X_test)

    # Train the model.
    if model_name == 'lr':
        reg = LinearRegression().fit(X_train, y_train)
    elif model_name == 'dt':
        reg = DecisionTreeRegressor(random_state=0).fit(X_train, y_train)
    elif model_name == 'rf':
        reg = RandomForestRegressor(random_state=0).fit(X_train, y_train)
    else:
        raise ValueError(model_name)

    # Predict the test set.
    y_pred = reg.predict(X_test)

    # Compute the R2 score.
    print(r2_score(y_test, y_pred))

    with open(os.path.join(reports_dir, f'regressor_{model_name}_{dataset_name}_{eval_backbone}_{post_resizer}_{n_samples}.pickle'), 'wb') as handle:
        pickle.dump(reg, handle, protocol=pickle.HIGHEST_PROTOCOL)

    # Print the feature importances from regressor.
    print(list(X.keys()))
    if model_name == 'lr':
        print(reg.coef_)
    elif model_name == 'dt':
        print(reg.feature_importances_)
    elif model_name == 'rf':
        print(reg.feature_importances_)
    else:
        raise ValueError(model_name)

    # Save to text file the valuee and save it.
    with open(os.path.join(reports_dir, f'regressor_{model_name}_{dataset_name}_{eval_backbone}_{post_resizer}_{n_samples}.txt'), 'w') as f:
        f.write(f"r2_score: {r2_score(y_test, y_pred)}\n")
        f.write(f"features: {list(X.keys())}\n")
        if model_name == 'lr':
            f.write(f"coef: {reg.coef_}\n")
        elif model_name == 'dt':
            f.write(f"feature_importances: {reg.feature_importances_}\n")
        elif model_name == 'rf':
            f.write(f"feature_importances: {reg.feature_importances_}\n")
        else:
            raise ValueError(model_name)

    print("May be the force with you.")

